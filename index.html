<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Common Pets in 3D: Dynamic New-View Synthesis of Real-Life Deformable Categories.">
  <meta name="keywords" content="CoP3D, TrackRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Common Pets in 3D: Dynamic New-View Synthesis of Real-Life Deformable Categories</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Common Pets in 3D: Dynamic New-View Synthesis of Real-Life Deformable Categories</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://samsinha.me">Samarth Sinha</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=icaQKyIAAAAJ&hl=en">Roman Shapovalov</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.co.uk/citations?user=35Rk1bQAAAAJ&hl=en">Jeremy Reizenstein</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.irocco.info/">Ignacio Rocco</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://nneverova.github.io/">Natalia Neverova</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.robots.ox.ac.uk/~vedaldi/">Andrea Vedaldi</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://d-novotny.github.io/">David Novotny</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Meta AI</span>
            <span class="author-block"><sup>2</sup>University of Toronto</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2211.03889"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2211.03889"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2211.03889"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Obtaining photorealistic reconstructions of objects from
            sparse views is inherently ambiguous and can only be
            achieved by learning suitable reconstruction priors. 
          </p>
          <p>
            Earlier works on sparse rigid object reconstruction successfully
            learned such priors from large datasets such as CO3D. In
            this paper, we extend this approach to dynamic objects. We
            use cats and dogs as a representative example and introduce
            Common Pets in 3D (CoP3D), a collection of crowd-sourced
            videos showing around 4,200 distinct pets. CoP3D is one of
            the first large-scale datasets for benchmarking non-rigid 3D
            reconstruction “in the wild”. 
          </p>
          <p>
            We also propose Tracker-NeRF,
            a method for learning 4D reconstruction from our dataset.
            At test time, given a small number of video frames of an unseen object, 
            Tracker-NeRF predicts the trajectories of its 3D
            points and generates new views, interpolating viewpoint and
            time. Results on CoP3D reveal significantly better non-rigid
            new-view synthesis performance than existing baselines.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{sinha2022common,
  title={Common Pets in 3D: Dynamic New-View Synthesis of Real-Life Deformable Categories},
  author={Sinha, Samarth and Shapovalov, Roman and Reizenstein, Jeremy and Rocco, Ignacio and Neverova, Natalia and Vedaldi, Andrea and Novotny, David},
  journal={CVPR},
  year={2023}
}</code></pre>
  </div>
</section>

</body>
</html>
